The data is stored in ./UCI_HAR_Dataset and comes from [Smartphones Mobility study](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) Here are the data for 
the project:
https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip

For each record it is provided: ====================================== 
- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration. 
- Triaxial Angular velocity from the gyroscope. 
- A 561-feature vector with time and frequency domain variables. Features are listed in features.txt, the variable values are in X_train.txt and X_test.txt 
- Its activity label, in activity_labels.txt
- An identifier of the subject who carried out the experiment, in train/subjects_train.txt and test/subjects_test.txt for train and test data respectively 
The dataset includes the following files: ========================================= 
- 'README.txt' 
- 'features_info.txt': Shows information about the variables used on the feature vector. 
- 'features.txt': List of all features. 
- 'activity_labels.txt': Links the class labels with their activity name. 
- 'train/X_train.txt': Training set. 
- 'train/y_train.txt': Training labels. 
- 'test/X_test.txt': Test set. 
- 'test/y_test.txt': Test labels. The following files are available for the train and test data. Their descriptions are equivalent. 
- 'train/subject_train.txt': Each row identifies the subject who performed the activity for each window sample. It the smartphone accelerometer X axis in standard gravity units 'g'. Every row shows a 128 element 
vector. 
- Features are normalized and bounded within [-1,1]. 
- Each feature vector is a rowfile. 
- The units used for the accelerations (total and body) arts are rad/seg.
- A video of the exe seen in the following link: http:: activityrecognition
